{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZjNqTQeHDq1P",
   "metadata": {
    "id": "ZjNqTQeHDq1P"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16354bd-ca40-4f17-a6b6-384a63a99dc7",
   "metadata": {
    "id": "d16354bd-ca40-4f17-a6b6-384a63a99dc7"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.sandbox.google.com/github/https-deeplearning-ai/sc-gc-c4-gemini-public/blob/main/lesson-5/L5_colab_videos.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac2391-3a90-4c2a-b860-55356a8b8930",
   "metadata": {
    "id": "bfac2391-3a90-4c2a-b860-55356a8b8930"
   },
   "source": [
    "# Cost Estimate\n",
    "\n",
    "The estimated cost of running this notebook once using your Google Cloud account, using `Gemini 1.5 Flash`, without \"Finding a Needle in a Haystack\" example (which has been converted to markdown) should be less than 0.20 USD (as of August 2024). Get the latest Gemini costs [here](https://cloud.google.com/vertex-ai/generative-ai/pricing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WVSuCx8fAlCJ",
   "metadata": {
    "id": "WVSuCx8fAlCJ"
   },
   "source": [
    "# SETUP\n",
    "\n",
    "This is follow up to the [How to Set Up your Google Cloud Account](https://learn.deeplearning.ai/courses/large-multimodal-model-prompting-with-gemini/lesson/9/how-to-set-up-your-google-cloud-account-|-try-it-out-yourself-[optional]) instructions from the course, [Large Multimodal Model Prompting with Gemini](https://learn.deeplearning.ai/courses/large-multimodal-model-prompting-with-gemini/lesson/1/introduction) on the [Learning Platform](https://learn.deeplearning.ai) of [DeepLearning.AI](https://www.deeplearning.ai)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kxyOUgGuD1cB",
   "metadata": {
    "id": "kxyOUgGuD1cB"
   },
   "source": [
    "### Install Vertex AI SDK and other Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fV6kVGI6D3Qx",
   "metadata": {
    "id": "fV6kVGI6D3Qx"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --user --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ohM3m2TBD4-A",
   "metadata": {
    "id": "ohM3m2TBD4-A"
   },
   "source": [
    "### Restart Runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
    "\n",
    "The restart might take a minute or longer. After it's restarted, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "_VFkGMCxD7IS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_VFkGMCxD7IS",
    "outputId": "434042ee-5de4-4f3a-c4ce-9bb9c74135f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7wBEATTEEII5",
   "metadata": {
    "id": "7wBEATTEEII5"
   },
   "source": [
    "### Authenticate your Notebook Environment (Colab Only)\n",
    "\n",
    "If you're running this notebook on Google Colab, run the cell below to authenticate your environment.\n",
    "\n",
    "**NOTE:** The Gmail email address you use to authenticate this lesson colab must be the same as the one you used to set up your Google Cloud account and your Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "NHvtRAsQEJUE",
   "metadata": {
    "id": "NHvtRAsQEJUE"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wcjLp7syENBX",
   "metadata": {
    "id": "wcjLp7syENBX"
   },
   "source": [
    "### Set Google Cloud Project Information and Initialize Vertex AI SDK\n",
    "\n",
    "**Add _your_ Project ID below**, which you created while following the [How to Set Up your Google Cloud Account](https://learn.deeplearning.ai/courses/large-multimodal-model-prompting-with-gemini/lesson/9/how-to-set-up-your-google-cloud-account-|-try-it-out-yourself-[optional]) instructions. If your `Project ID` was `dlai-shortcourse-on-gemini`, then you can run the cell below as it is. Otherwise, be sure to change it.\n",
    "\n",
    "You can also look up your Project ID in your [Project Dashboard](https://console.cloud.google.com/projectselector2/home/dashboard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1WDlDM8uENqR",
   "metadata": {
    "id": "1WDlDM8uENqR"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"dlai-shortcourse-on-gemini\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CJspoqjXBOgZ",
   "metadata": {
    "id": "CJspoqjXBOgZ"
   },
   "source": [
    "# IN COURSE VIDEO\n",
    "\n",
    "Lesson video starts from below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679851f7-54ed-437d-ae67-1d173913bb28",
   "metadata": {
    "id": "679851f7-54ed-437d-ae67-1d173913bb28"
   },
   "source": [
    "# [Lesson 5: Developing Use Cases with Videos](https://learn.deeplearning.ai/courses/large-multimodal-model-prompting-with-gemini/lesson/6/developing-use-cases-videos)\n",
    "\n",
    "In this lesson, you'll go through Gemini's Multimodality capabilities, by passing Videos and Texts as input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14c80d-e9e2-4ba2-9362-388736225365",
   "metadata": {
    "id": "7a14c80d-e9e2-4ba2-9362-388736225365"
   },
   "source": [
    "**Note:** In the latest version, `from vertexai.preview.generative_models` has been changed to `from vertexai.generative_models`.\n",
    "\n",
    "`from vertexai.preview.generative_models` can still be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27015df2-de75-4a34-9756-ef5ffc58a647",
   "metadata": {
    "id": "27015df2-de75-4a34-9756-ef5ffc58a647",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.generative_models import GenerativeModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507beaa1-662b-4a78-90f0-6218c4c91d00",
   "metadata": {
    "id": "507beaa1-662b-4a78-90f0-6218c4c91d00"
   },
   "source": [
    "Please note that Google's Gemini model `gemini-pro-vision` (`gemini-1.0-pro-vision`) [is being deprecated (soon)](https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations). Therefore, it is necessary to switch to the recommended replacement model, `gemini-2.0-flash`.\n",
    "\n",
    "- Load the [gemini-2.0-flash](https://ai.google.dev/gemini-api/docs/models#gemini-2.0-flash) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d49b1dae-ecdd-4c31-bd23-770890273382",
   "metadata": {
    "id": "d49b1dae-ecdd-4c31-bd23-770890273382",
    "tags": []
   },
   "outputs": [],
   "source": [
    "multimodal_model = GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cb7797-709f-450f-bc35-6a8df4eab2fe",
   "metadata": {
    "id": "99cb7797-709f-450f-bc35-6a8df4eab2fe"
   },
   "source": [
    "## Digital Marketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0970ab-f175-47c1-95f0-aa815b0cbe7f",
   "metadata": {
    "id": "4f0970ab-f175-47c1-95f0-aa815b0cbe7f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path_1 = \"dlai-sc-gemini-bucket/vertex-ai-langchain.mp4\"\n",
    "video_uri_1 = f\"gs://{file_path_1}\"\n",
    "video_url_1 = f\"https://storage.googleapis.com/{file_path_1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d49ab4a5-66ee-492e-abc8-01c3de7b8bf0",
   "metadata": {
    "id": "d49ab4a5-66ee-492e-abc8-01c3de7b8bf0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbcb3eda-4c1b-4d9d-abcb-445de4001d0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "bbcb3eda-4c1b-4d9d-abcb-445de4001d0e",
    "outputId": "26194c41-59e3-4cd0-fc50-6e7ed33c6191",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://storage.googleapis.com/dlai-sc-gemini-bucket/vertex-ai-langchain.mp4\" controls  width=\"450\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Video(video_url_1, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3884d16-1ad1-4b51-9df4-af2d01ee5d48",
   "metadata": {
    "id": "c3884d16-1ad1-4b51-9df4-af2d01ee5d48",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f3ed51-3275-4ecd-979c-7e8b7a4576ad",
   "metadata": {
    "id": "78f3ed51-3275-4ecd-979c-7e8b7a4576ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_1 = Part.from_uri(video_uri_1, mime_type=\"video/mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7fe8a7-9a36-4507-ba6d-eeb65eaf4de3",
   "metadata": {
    "id": "3a7fe8a7-9a36-4507-ba6d-eeb65eaf4de3"
   },
   "source": [
    "- Structure your prompt(s).\n",
    "- Be specific with what you want the model to do for you.\n",
    "- You can even specify the output format of the response from the model.\n",
    "- In this case, you are asking for the response to be in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "945f492e-1abf-402f-b449-361620ee10b9",
   "metadata": {
    "id": "945f492e-1abf-402f-b449-361620ee10b9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = \"\"\"\n",
    "You are a great digital marketer working on a new video.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a759702-d13c-47cf-a858-61c60f89b95a",
   "metadata": {
    "id": "6a759702-d13c-47cf-a858-61c60f89b95a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasks = \"\"\"\n",
    "You will add the video to your website and to do this you\n",
    "need to complete some tasks. Please make sure your answer\n",
    "is structured.\n",
    "\n",
    "Tasks:\n",
    "- What is the title of the video?\n",
    "- Write a summary of what is in the video.\n",
    "- Generate metadata for the video in JSON that includes:\\\n",
    "Title, short description, language, and company.\n",
    "\"\"\"\n",
    "\n",
    "# tasks = \"\"\"\n",
    "# You will add the video to your website and to do this you\n",
    "# need to complete some tasks. Please make sure your answer\n",
    "# is structured.\n",
    "\n",
    "# Tasks:\n",
    "# - What is the title of the video?\n",
    "# - Write a summary of what is in the video.\n",
    "# - Generate metadata for the video that includes:\\\n",
    "# Title, short description, language, and company.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8bdbed-890c-435d-90ba-6328722dac39",
   "metadata": {
    "id": "fb8bdbed-890c-435d-90ba-6328722dac39"
   },
   "source": [
    "- You can choose the number of variables you want for your prompt.\n",
    "- More variables means you have more flexibility in making specific changes to your prompts while keeping everyhting else the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791c1d6-39af-44f6-b633-212df6315138",
   "metadata": {
    "id": "9791c1d6-39af-44f6-b633-212df6315138",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# format_json = \"Please output the metadata in JSON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1185aa10-ece7-473d-aaa5-243185e84d42",
   "metadata": {
    "id": "1185aa10-ece7-473d-aaa5-243185e84d42",
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents_1 = [video_1, role, tasks]\n",
    "\n",
    "# contents_1 = [video_1, role, tasks, format_json]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171592df-1777-4b32-99ac-ff0ac42eadda",
   "metadata": {
    "id": "171592df-1777-4b32-99ac-ff0ac42eadda"
   },
   "source": [
    "- Feel free to change the `temperature`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8527c49-8a9f-4f8f-988f-5ccc8dc216d3",
   "metadata": {
    "id": "d8527c49-8a9f-4f8f-988f-5ccc8dc216d3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_config_1 = GenerationConfig(\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40e4e8d7-8028-46d4-9eac-6e2dc803db17",
   "metadata": {
    "id": "40e4e8d7-8028-46d4-9eac-6e2dc803db17",
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = multimodal_model.generate_content(\n",
    "    contents_1,\n",
    "    generation_config=generation_config_1,\n",
    "    stream=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16350384-1495-4ebc-9ddf-0b0746525a0c",
   "metadata": {
    "id": "16350384-1495-4ebc-9ddf-0b0746525a0c"
   },
   "source": [
    "**Note**: If you set `stream=True`, you'll print your responses as:\n",
    "```Python\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c4d91-1251-4b83-a4e8-89075e33c49c",
   "metadata": {
    "id": "3a6c4d91-1251-4b83-a4e8-89075e33c49c"
   },
   "source": [
    "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "956a46c4-e4e4-4979-9c1b-bebec2f05fb1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "956a46c4-e4e4-4979-9c1b-bebec2f05fb1",
    "outputId": "a8283c30-9997-4b96-9d1a-7728b7bd7475",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I can help you with that! Here's the information you requested:\n",
      "\n",
      "**Title of the Video:**\n",
      "\n",
      "Build AI-powered apps on Vertex AI with LangChain\n",
      "\n",
      "**Summary of the Video:**\n",
      "\n",
      "This video explains how to build AI-powered applications using Google Cloud's Vertex AI and the LangChain framework. It starts by introducing the concept of generative AI and how it helps developers build various applications. The video then discusses the challenges of using large language models (LLMs) out-of-the-box, such as their limited access to knowledge and the need to orchestrate multiple steps for complex use cases.\n",
      "\n",
      "The video introduces LangChain as a framework that offers flexible abstractions for building LLM-driven applications. It highlights LangChain's data-aware and agentic capabilities, enabling models to connect to external data sources and interact with their environment.\n",
      "\n",
      "The video also explains how Vertex AI integrates with LangChain's Python SDK, making it easier to build applications on top of Vertex AI. It mentions Vertex AI's integrations with services like PaLM API for text, chat, and embeddings, as well as Vertex AI Vector Search and Vertex AI Search.\n",
      "\n",
      "Finally, the video provides a basic code example of using the PaLM API and LangChain for summarizing large documents and discusses use cases such as improving customer support through chat, exploring unstructured data, and summarizing large documents.\n",
      "\n",
      "**Metadata in JSON Format:**\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"title\": \"Build AI-powered apps on Vertex AI with LangChain\",\n",
      "  \"short_description\": \"Learn how to build AI-powered applications using Google Cloud's Vertex AI and the LangChain framework.\",\n",
      "  \"language\": \"en\",\n",
      "  \"company\": \"Google Cloud\"\n",
      "}\n",
      "```\n",
      "\n",
      "I hope this helps you with your website! Let me know if you need anything else.\n"
     ]
    }
   ],
   "source": [
    "print(responses.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9b1931-8e9a-4ac2-84cc-445df7c9743f",
   "metadata": {
    "id": "4a9b1931-8e9a-4ac2-84cc-445df7c9743f"
   },
   "source": [
    "# Explaining the Educational Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "054120fd-cf97-4e5b-92b8-11fd7e2b3771",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "054120fd-cf97-4e5b-92b8-11fd7e2b3771",
    "outputId": "09b3c02f-2498-4641-c18b-9854a89ef061",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://storage.googleapis.com/dlai-sc-gemini-bucket/descending-into-ml.mp4\" controls  width=\"450\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_2 = \"dlai-sc-gemini-bucket/descending-into-ml.mp4\"\n",
    "video_uri_2 = f\"gs://{file_path_2}\"\n",
    "video_url_2 = f\"https://storage.googleapis.com/{file_path_2}\"\n",
    "\n",
    "IPython.display.Video(video_url_2, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e9be4b6-f508-4cd0-b885-cdb60bc6280b",
   "metadata": {
    "id": "3e9be4b6-f508-4cd0-b885-cdb60bc6280b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_2 = Part.from_uri(video_uri_2, mime_type=\"video/mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5bb786-74bf-40c7-ab55-f8b6f031ee1c",
   "metadata": {
    "id": "7a5bb786-74bf-40c7-ab55-f8b6f031ee1c"
   },
   "source": [
    "- You can even ask the model to answer based on answers of previous questions.\n",
    "- And to generate programming code based on previous answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fa902fe-91f6-48f7-ae0d-4792f35398a5",
   "metadata": {
    "id": "3fa902fe-91f6-48f7-ae0d-4792f35398a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Please have a look at the video and answer the following\n",
    "questions.\n",
    "\n",
    "Questions:\n",
    "- Question 1: Which concept is explained in the video?\n",
    "- Question 2: Based on your answer to Question 1,\n",
    "can you explain the basic math of this concept?\n",
    "- Question 3: Can you provide a simple scikit code example\n",
    "explaining the concept?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d24e5781-4f61-4d44-a7b6-4ce497fc54da",
   "metadata": {
    "id": "d24e5781-4f61-4d44-a7b6-4ce497fc54da",
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents_2 = [video_2, prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29a15d96-8d6f-4a71-b5c2-3b00fe54eeb2",
   "metadata": {
    "id": "29a15d96-8d6f-4a71-b5c2-3b00fe54eeb2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = multimodal_model.generate_content(\n",
    "    contents_2,\n",
    "    stream=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d093c488-d7bd-4210-8ac5-550daa6ce614",
   "metadata": {
    "id": "d093c488-d7bd-4210-8ac5-550daa6ce614"
   },
   "source": [
    "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c8901fc-8ee7-4055-93d5-bca892c16d04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c8901fc-8ee7-4055-93d5-bca892c16d04",
    "outputId": "60d136e9-bd93-4fb6-d38d-67f93f79748b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let’s have a look at the video and try to answer the questions you posed.\n",
      "\n",
      "- Question 1: Which concept is explained in the video?\n",
      "\n",
      "The video is explaining the concept of a linear regression model, used for predicting housing prices based on housing square footage. The video illustrates how to train this linear regression model to fit a line of best fit through data, as well as an L2 loss function, otherwise known as squared error.\n",
      "\n",
      "- Question 2: Based on your answer to Question 1, can you explain the basic math of this concept?\n",
      "\n",
      "The video explains the basic math of a linear regression model as follows:\n",
      "*   Y = wX+b\n",
      "    *   Y represents the target value that you want to predict (in this case house price).\n",
      "    *   X represents the input feature (in this case house square footage).\n",
      "    *   W is the weight that is multiplied by the input feature X to calculate Y\n",
      "    *   b is a bias that accounts for the difference between the predicted value vs the true value.\n",
      "\n",
      "- Question 3: Can you provide a simple scikit code example explaining the concept?\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.metrics import mean_squared_error\n",
      "\n",
      "# Sample data (house square footage and house price)\n",
      "X = np.array([1000, 1200, 1500, 1800, 2000]).reshape((-1, 1))  # Square footage\n",
      "y = np.array([250000, 300000, 375000, 450000, 500000])  # House price\n",
      "\n",
      "# Create a linear regression model\n",
      "model = LinearRegression()\n",
      "\n",
      "# Train the model using the sample data\n",
      "model.fit(X, y)\n",
      "\n",
      "# Make predictions\n",
      "y_pred = model.predict(X)\n",
      "\n",
      "# Evaluate the model using mean squared error (L2 loss)\n",
      "mse = mean_squared_error(y, y_pred)\n",
      "\n",
      "# Print the model parameters and evaluation metric\n",
      "print('Intercept:', model.intercept_)\n",
      "print('Coefficient:', model.coef_)\n",
      "print('Mean Squared Error:', mse)\n",
      "\n",
      "# You can now use this trained model to predict house prices for new square footage values\n",
      "new_square_footage = np.array([1600]).reshape((-1, 1))\n",
      "predicted_price = model.predict(new_square_footage)\n",
      "print('Predicted price for 1600 sq ft:', predicted_price[0])\n",
      "```\n",
      "\n",
      "Explanation:\n",
      "*   The sample is first defined using numpy.\n",
      "*   The linear regression model is defined using “LinearRegression()”\n",
      "*   To train, the model, the X and y parameters are fitted to the linear regression model using the function call “model.fit(X,y)”\n",
      "*   “y_pred = model.predict(X)”: This predicts the values using the data\n",
      "*   “mean_squared_error(y, y_pred)”:  The “mean_squared_error” method calculates the difference between all of the data. In this example we have the predicted “y_pred” values and the actual values “y”.\n",
      "*   Finally a value is used to predict the house price.\n"
     ]
    }
   ],
   "source": [
    "print(responses.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da9100-165b-4968-a14d-b264c86f574b",
   "metadata": {
    "id": "09da9100-165b-4968-a14d-b264c86f574b"
   },
   "source": [
    "- You can copy/paste and run your generated code in the cell below.\n",
    "\n",
    "**Note:** LLM's are known to generate code which is incomplete or has bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8568ea9-8c05-48b4-b3c5-84e0f83a5a8d",
   "metadata": {
    "id": "d8568ea9-8c05-48b4-b3c5-84e0f83a5a8d"
   },
   "outputs": [],
   "source": [
    "### you can copy/paste your generated code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23746f67-e028-40e7-879e-790aef78dffa",
   "metadata": {
    "id": "23746f67-e028-40e7-879e-790aef78dffa"
   },
   "source": [
    "- Below cell includes the code which was generated in the lecture video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e156d4-9e2d-4c99-9250-cb853e5ff397",
   "metadata": {
    "id": "64e156d4-9e2d-4c99-9250-cb853e5ff397",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Import the necessary libraries\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # Create some data\n",
    "# X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "# y = np.dot(X, np.array([1, 2])) + 3\n",
    "\n",
    "# # Fit the linear regression model\n",
    "# model = LinearRegression()\n",
    "# model.fit(X, y)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = model.predict(X)\n",
    "\n",
    "# # Plot the data and the fitted line\n",
    "# plt.scatter(X[:, 1], y)\n",
    "# plt.plot(X[:, 1], y_pred, color='red')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9d06e1-a537-46dd-bd7b-5ad3cedce500",
   "metadata": {
    "id": "bc9d06e1-a537-46dd-bd7b-5ad3cedce500"
   },
   "source": [
    "## Extracting Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "537892cf-d107-4542-98b8-f381ede35a07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "537892cf-d107-4542-98b8-f381ede35a07",
    "outputId": "d010dfde-1505-4002-9817-3bbec031cf98",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://storage.googleapis.com/dlai-sc-gemini-bucket/google-search.mp4\" controls  width=\"450\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_4 = \"dlai-sc-gemini-bucket/google-search.mp4\"\n",
    "video_uri_4 = f\"gs://{file_path_4}\"\n",
    "video_url_4 = f\"https://storage.googleapis.com/{file_path_4}\"\n",
    "\n",
    "IPython.display.Video(video_url_4, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d2a8301-2ff1-4e42-a93f-0e79ac467730",
   "metadata": {
    "id": "6d2a8301-2ff1-4e42-a93f-0e79ac467730",
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_4 = Part.from_uri(video_uri_4, mime_type=\"video/mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1adb0e3-44b5-4701-8a37-2acb7a6d3d10",
   "metadata": {
    "id": "d1adb0e3-44b5-4701-8a37-2acb7a6d3d10"
   },
   "source": [
    "**Note:** In the lecture video, everything was put in a single prompt (`prompt_4`):\n",
    "\n",
    "```Python\n",
    "prompt_4 = \"\"\"\n",
    "Answer the following questions using the video only.\n",
    "Present the results in a table with a row for each question\n",
    "and its answer.\n",
    "Make sure the table is in markdown format.\n",
    "\n",
    "Questions:\n",
    "- What is the most searched sport?\n",
    "- Who is the most searched scientist?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "contents_4 = [video_4, prompt_4]\n",
    "```\n",
    "But as also mentioned in the lecture, you can break it into seperate variables (`questions` and `format_html`), as done in the notebook below. Feel free to pause the video and compare your notebook with the video to see the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a11497-5a76-4d00-93b6-2d2f701d4474",
   "metadata": {
    "id": "e2a11497-5a76-4d00-93b6-2d2f701d4474"
   },
   "source": [
    "- Here, you have your questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7061e11d-b17b-4f7a-96fb-ec1515a6d2a4",
   "metadata": {
    "id": "7061e11d-b17b-4f7a-96fb-ec1515a6d2a4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions = \"\"\"\n",
    "Answer the following questions using the video only.\n",
    "\n",
    "Questions:\n",
    "- What is the most searched sport?\n",
    "- Who is the most searched scientist?\n",
    "\"\"\"\n",
    "\n",
    "# questions = \"\"\"\n",
    "# Answer the following questions using the video only.\n",
    "# If the answer is not found in the video,\n",
    "# say \"Not found in video\".\n",
    "\n",
    "# Questions:\n",
    "# - What is the most searched sport?\n",
    "# - Who is the most searched scientist?\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b134862-4be8-4373-96aa-15f90b985396",
   "metadata": {
    "id": "3b134862-4be8-4373-96aa-15f90b985396"
   },
   "source": [
    "- Here, you specify the output format.\n",
    "- In this case, it is table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0c633fa-b953-474b-a8e8-7bbfe7d919b0",
   "metadata": {
    "id": "a0c633fa-b953-474b-a8e8-7bbfe7d919b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "format_html = \"\"\"\n",
    "Format:\n",
    "Present the results in a table with a row for each question\n",
    "and its answer.\n",
    "Make sure the table is in markdown format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf756730-718f-47c4-82e9-2b598fc35b44",
   "metadata": {
    "id": "cf756730-718f-47c4-82e9-2b598fc35b44",
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents_4 = [video_4, questions, format_html]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14840809-732a-45f2-9222-c7c5faef0cb5",
   "metadata": {
    "id": "14840809-732a-45f2-9222-c7c5faef0cb5"
   },
   "source": [
    "- Set the `temperature`. For now, it is `temperature=0.9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e9b0ab0-7955-49a7-8f0c-5d106ae469db",
   "metadata": {
    "id": "9e9b0ab0-7955-49a7-8f0c-5d106ae469db",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_config_1 = GenerationConfig(\n",
    "    temperature=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6a09877-2d8a-46f6-b1eb-5389151f927a",
   "metadata": {
    "id": "a6a09877-2d8a-46f6-b1eb-5389151f927a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = multimodal_model.generate_content(contents_4,\n",
    "                   generation_config=generation_config_1,\n",
    "                                              stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac63287-d25b-4b13-84c1-852c6f5b708e",
   "metadata": {
    "id": "1ac63287-d25b-4b13-84c1-852c6f5b708e"
   },
   "source": [
    "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afd17035-a22d-48f8-9850-bd2a8d8e1568",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afd17035-a22d-48f8-9850-bd2a8d8e1568",
    "outputId": "7fd2c20b-c7a8-4bee-bbd4-bfe77848f5ad",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK, here is the information you requested:\n",
      "\n",
      "| Question                                   | Answer             |\n",
      "| :----------------------------------------- | :----------------- |\n",
      "| What is the most searched sport?          | Soccer             |\n",
      "| Who is the most searched scientist?     | Albert Einstein    |"
     ]
    }
   ],
   "source": [
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d527184e-4b9e-404f-ac58-7510110fb006",
   "metadata": {
    "id": "d527184e-4b9e-404f-ac58-7510110fb006"
   },
   "source": [
    "```\n",
    "You can copy/paste your generation in this Markdown cell (double click here)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39889919-f32c-4fe6-a5d2-3ebcccacc3c4",
   "metadata": {
    "id": "39889919-f32c-4fe6-a5d2-3ebcccacc3c4"
   },
   "source": [
    "## Finding a Needle in a Haystack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7f61b-2f04-4226-b905-9c714573ba63",
   "metadata": {
    "id": "e9e7f61b-2f04-4226-b905-9c714573ba63"
   },
   "source": [
    "Please note that Google's Gemini model `gemini-1.5-pro-001` [is being deprecated (soon)](https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations). Therefore, it is necessary to switch to the recommended replacement model, `gemini-2.0-flash`.\n",
    "\n",
    "- Load the [gemini-2.0-flash](https://ai.google.dev/gemini-api/docs/models#gemini-2.0-flash) model.\n",
    "\n",
    "<span style=\"color:red; font-weight:bold;\">IMPORTANT ⚠️: Propmting NEEDLE IN A HAYSTACK example is a costly execution, please review the [cost](https://cloud.google.com/vertex-ai/generative-ai/pricing) before running it.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1eca11af-1cd6-4b70-96e7-1b20898de566",
   "metadata": {
    "id": "1eca11af-1cd6-4b70-96e7-1b20898de566",
    "tags": []
   },
   "outputs": [],
   "source": [
    "multimodal_model = GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e54edcd-4c29-411e-aabf-c5b26e48b8f7",
   "metadata": {
    "id": "5e54edcd-4c29-411e-aabf-c5b26e48b8f7"
   },
   "source": [
    "- Just like with images, you can send more than 1 video to the model.\n",
    "- The following videos are from the **[LLMOps](https://learn.deeplearning.ai/courses/llmops/lesson/1/introduction)** short course, which you can enroll in on **[DeepLearning.AI's Short Courses Platform](https://learn.deeplearning.ai)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c28074ef-2c8c-4008-a83e-c8b3140eeb9a",
   "metadata": {
    "id": "c28074ef-2c8c-4008-a83e-c8b3140eeb9a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_1 = Part.from_uri(\"gs://dlai-sc-gemini-bucket/sc-gc-c3-LLMOps_L1_v3.mp4.mp4\",  mime_type=\"video/mp4\")\n",
    "video_2 = Part.from_uri(\"gs://dlai-sc-gemini-bucket/sc-gc-c3-LLMOps_L2_v4.mp4\",  mime_type=\"video/mp4\")\n",
    "video_3 = Part.from_uri(\"gs://dlai-sc-gemini-bucket/sc-gc-c3-LLMOps_L3_v4.mp4\",  mime_type=\"video/mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "555ad4b4-9918-4fbc-8ecb-d957a16d8b4a",
   "metadata": {
    "id": "555ad4b4-9918-4fbc-8ecb-d957a16d8b4a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c384cb3-c0d5-4ac8-a4f3-8340f92a4d96",
   "metadata": {
    "id": "3c384cb3-c0d5-4ac8-a4f3-8340f92a4d96"
   },
   "source": [
    "- This displays only one of the three videos.\n",
    "- To view others, feel free to change the `file_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17f6bdb1-8c6d-4e5c-83fb-294507a6f37d",
   "metadata": {
    "id": "17f6bdb1-8c6d-4e5c-83fb-294507a6f37d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"dlai-sc-gemini-bucket/sc-gc-c3-LLMOps_L2_v4.mp4\"\n",
    "video_url = f\"https://storage.googleapis.com/{file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e26e417-56e2-4d0c-a955-374c675f868f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "7e26e417-56e2-4d0c-a955-374c675f868f",
    "outputId": "dcaad3f3-2b35-469e-b252-7932ca4a3e09",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"560\"\n",
       "            height=\"315\"\n",
       "            src=\"https://storage.googleapis.com/dlai-sc-gemini-bucket/sc-gc-c3-LLMOps_L2_v4.mp4\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7a602a42f010>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(video_url, width=560, height=315)  # Adjust width and height as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a70ed794-959c-4777-8fad-00e7b20a541d",
   "metadata": {
    "id": "a70ed794-959c-4777-8fad-00e7b20a541d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = \"\"\"\n",
    "You are specialized in analyzing videos and finding \\\n",
    "a needle in a haystack.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4df3088-f7ed-43b6-b148-1fb7549797d6",
   "metadata": {
    "id": "f4df3088-f7ed-43b6-b148-1fb7549797d6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "Here are three videos. Each is a lesson from the \\\n",
    "LLMOps course from Deep Learning AI.\n",
    "Your answers are only based on the videos.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04e5717-1495-4d69-93a2-93e0e3fc1959",
   "metadata": {
    "id": "c04e5717-1495-4d69-93a2-93e0e3fc1959"
   },
   "source": [
    "- You are asking the model (question 2) to find something very specific from across these 3 videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4dbcc5af-aca5-4f1b-82cd-36966fb690e2",
   "metadata": {
    "id": "4dbcc5af-aca5-4f1b-82cd-36966fb690e2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions = \"\"\"\n",
    "Answer the following questions:\n",
    "1. Create a summary of each video and what is discussed in \\\n",
    "the video.\\\n",
    "Limit the summary to a max of 100 words.\n",
    "2. In which of the three videos does the instructor run \\\n",
    "and explains this Python code: bq_client.query(). \\\n",
    "Where do you see this code in the video?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cda6a861-271a-4acb-ab84-8cac8ce0a9b3",
   "metadata": {
    "id": "cda6a861-271a-4acb-ab84-8cac8ce0a9b3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents_5 = [\n",
    "    role,\n",
    "    instruction,\n",
    "    video_1,\n",
    "    video_2,\n",
    "    video_3,\n",
    "    questions\n",
    "]\n",
    "\n",
    "# contents_5 = [\n",
    "#     instruction,\n",
    "#     video_1,\n",
    "#     video_2,\n",
    "#     video_3,\n",
    "#     questions,\n",
    "#     role,\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab0a1be-1035-4648-9aa2-2b35e0766423",
   "metadata": {
    "id": "fab0a1be-1035-4648-9aa2-2b35e0766423"
   },
   "source": [
    "**Note:** We have commented out the code to prevent accidental execution\n",
    "\n",
    "```Python\n",
    "responses = multimodal_model.generate_content(\n",
    "    contents_5,\n",
    "    stream=True\n",
    ")\n",
    "```\n",
    "\n",
    "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get.\n",
    "\n",
    "```Python\n",
    "### this will take some time to run\n",
    "\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "YSGuJqjgD-2I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YSGuJqjgD-2I",
    "outputId": "78a5542c-b9fa-4ab3-a353-80b026be584e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I'm ready to analyze the videos.\n",
      "\n",
      "Here's a breakdown of each video and the answers to your questions:\n",
      "\n",
      "**Video Summary 1: The Fundamentals**\n",
      "This lesson introduces the fundamental concepts and ideas behind LLMOps and contrasts it with MLops. The core principles such as data management, automation, monitoring, deployment, and infrastructure are explained. Automation is particularly emphasized. The presenter used a framework to explain data ingestion, data validation, data transformation, model creation, model analysis, serving, and logging. Then, it describes the use of Orchestration through job management, which defines a task to be performed and how the system will achieve the intended outcome.\n",
      "\n",
      "**Video Summary 2: Data Preparation**\n",
      "The lesson focuses on data preparation specifically for large language models. It explains how to retrieve data from Stack Overflow stored in a data warehouse, using SQL. It covered authentications to use Stack Overflow data. It also covered how to divide the data into training and evaluation sets, and how the data should be stored, using a data format of JSONL. It ended by specifying different best practices for working with these dataset and the reasoning behind its effectiveness.\n",
      "\n",
      "**Video Summary 3: Automation and Orchestration with Pipelines**\n",
      "This video introduces the automation and orchestration process using Kubeflow and pipelines. It mentions the use of Python functions to create a component to tell the system how it should perform the component. In addition to the use of Python, it touches the concepts of a domain-specific language (DSL). Then, it describes how to use an open-source Kubeflow pipeline to improve model performance and generalization.\n",
      "\n",
      "**Regarding the code `bq_client.query()`:**\n",
      "\n",
      "*   This code is run in **video 2** (Data Preparation).\n",
      "*   You can see this in video 2 starting from the timestamp \\[00:27:52]\n",
      "\n",
      "Let me know if you have any other questions!"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m114"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
